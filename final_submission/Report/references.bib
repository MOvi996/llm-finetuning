@inproceedings{abdullah-etal-2020-rediscovering,
    title = "Rediscovering the {S}lavic Continuum in Representations Emerging from Neural Models of Spoken Language Identification",
    author = {Abdullah, Badr M.  and
      Kudera, Jacek  and
      Avgustinova, Tania  and
      M{\"o}bius, Bernd  and
      Klakow, Dietrich},
    editor = {Zampieri, Marcos  and
      Nakov, Preslav  and
      Ljube{\v{s}}i{\'c}, Nikola  and
      Tiedemann, J{\"o}rg  and
      Scherrer, Yves},
    booktitle = "Proceedings of the 7th Workshop on NLP for Similar Languages, Varieties and Dialects",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics (ICCL)",
    url = "https://aclanthology.org/2020.vardial-1.12",
    pages = "128--139",
    abstract = "Deep neural networks have been employed for various spoken language recognition tasks, including tasks that are multilingual by definition such as spoken language identification (LID). In this paper, we present a neural model for Slavic language identification in speech signals and analyze its emergent representations to investigate whether they reflect objective measures of language relatedness or non-linguists{'} perception of language similarity. While our analysis shows that the language representation space indeed captures language relatedness to a great extent, we find perceptual confusability to be the best predictor of the language representation similarity.",
}

@misc{zaken2022bitfit,
      title={BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models}, 
      author={Elad Ben Zaken and Shauli Ravfogel and Yoav Goldberg},
      year={2022},
      eprint={2106.10199},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hu2021lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2022fewshot,
      title={Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning}, 
      author={Haokun Liu and Derek Tam and Mohammed Muqeeth and Jay Mohta and Tenghao Huang and Mohit Bansal and Colin Raffel},
      year={2022},
      eprint={2205.05638},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}